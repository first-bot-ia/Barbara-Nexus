"""
üèóÔ∏è Infrastructure Service: Gemini AI Service
Siguiendo principios de Domain-Driven Design (DDD)
"""

from typing import Optional, Dict, Any
import requests
import logging
import time

logger = logging.getLogger(__name__)

class GeminiAIService:
    """
    Infrastructure Service: Servicio para interactuar con Gemini AI
    
    Siguiendo DDD: Los servicios de infraestructura manejan 
    comunicaci√≥n con sistemas externos
    """
    
    def __init__(self, api_key: str):
        self.api_key = api_key
        self.base_url = "https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent"
        self.timeout = 15
        self.max_retries = 3
        
        # Configuraci√≥n optimizada para Barbara
        self.default_config = {
            'temperature': 0.4,  # Consistencia conversacional
            'topK': 20,
            'topP': 0.8,
            'maxOutputTokens': 120  # Respuestas cortas
        }
    
    def generate_response(self, 
                         message: str, 
                         conversation_context: str,
                         config: Optional[Dict[str, Any]] = None) -> Optional[str]:
        """
        Genera respuesta usando Gemini AI
        
        Args:
            message: Mensaje del usuario
            conversation_context: Contexto conversacional completo
            config: Configuraci√≥n personalizada (opcional)
            
        Returns:
            Respuesta generada o None si falla
        """
        
        try:
            # Preparar configuraci√≥n
            generation_config = {**self.default_config}
            if config:
                generation_config.update(config)
            
            # Construir prompt optimizado para Barbara
            prompt = self._build_barbara_prompt(message, conversation_context)
            
            # Hacer petici√≥n con reintentos
            for attempt in range(self.max_retries):
                try:
                    response = self._make_api_request(prompt, generation_config)
                    if response:
                        logger.info(f"‚úÖ Gemini respuesta generada (intento {attempt + 1})")
                        return response
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Gemini intento {attempt + 1} fall√≥: {e}")
                    if attempt < self.max_retries - 1:
                        time.sleep(1)  # Esperar antes del reintento
            
            logger.error("‚ùå Gemini fall√≥ despu√©s de todos los reintentos")
            return None
            
        except Exception as e:
            logger.error(f"‚ùå Error inesperado en Gemini: {e}")
            return None
    
    def _build_barbara_prompt(self, message: str, context: str) -> str:
        """Construye prompt optimizado para Barbara"""
        return f"""{context}

INSTRUCCIONES CR√çTICAS PARA BARBARA:

‚ö†Ô∏è NUNCA repitas las palabras del cliente como si fueran tuyas
‚ö†Ô∏è NUNCA incluyas frases como "Quiero Cotizar" en tu respuesta
‚ö†Ô∏è Solo responde como Barbara, no como el cliente

PERSONALIDAD:
- Eres Barbara, persona real que trabaja en Autofondo Alese
- Habla natural y humano, NO como robot
- USA el historial para NO repetir informaci√≥n
- Si ya tienes el nombre, NO lo pidas otra vez
- Mant√©n flujo natural sin redundancias
- NUNCA te presentes dos veces
- M√°ximo 2 l√≠neas de respuesta

REGLAS DE ORO:
1. Lee el contexto conversacional
2. Identifica qu√© dijo el CLIENTE vs qu√© dijo BARBARA
3. Responde SOLO como Barbara
4. NO repitas palabras del cliente

MENSAJE ACTUAL DEL CLIENTE: {message}

RESPUESTA DE BARBARA (m√°ximo 2 l√≠neas, sin repetir palabras del cliente):"""
    
    def _make_api_request(self, prompt: str, config: Dict[str, Any]) -> Optional[str]:
        """Hace la petici√≥n real a la API de Gemini"""
        
        url = f"{self.base_url}?key={self.api_key}"
        
        headers = {"Content-Type": "application/json"}
        
        data = {
            "contents": [{"parts": [{"text": prompt}]}],
            "generationConfig": config
        }
        
        response = requests.post(url, headers=headers, json=data, timeout=self.timeout)
        
        if response.status_code == 200:
            result = response.json()
            if 'candidates' in result and len(result['candidates']) > 0:
                content = result['candidates'][0]['content']['parts'][0]['text'].strip()
                return self._clean_response(content)
        
        # Log del error para debugging
        logger.error(f"‚ùå Gemini API error: {response.status_code} - {response.text}")
        raise Exception(f"Gemini API error: {response.status_code}")
    
    def _clean_response(self, response: str) -> str:
        """Limpia la respuesta de Gemini"""
        # Remover prefijos comunes
        prefixes_to_remove = [
            "RESPUESTA DE BARBARA:",
            "Barbara:",
            "Respuesta:",
            "RESPUESTA:"
        ]
        
        cleaned = response
        for prefix in prefixes_to_remove:
            if cleaned.startswith(prefix):
                cleaned = cleaned[len(prefix):].strip()
        
        # Remover asteriscos de markdown si est√°n solos
        cleaned = cleaned.replace("**", "").replace("*", "")
        
        return cleaned
    
    def health_check(self) -> bool:
        """Verifica si el servicio est√° funcionando"""
        try:
            test_response = self.generate_response(
                message="test",
                conversation_context="Test de conectividad",
                config={'maxOutputTokens': 10}
            )
            return test_response is not None
        except Exception:
            return False
    
    def get_service_info(self) -> Dict[str, Any]:
        """Obtiene informaci√≥n del servicio"""
        return {
            'service': 'Gemini AI',
            'model': 'gemini-1.5-flash',
            'status': 'active' if self.health_check() else 'error',
            'config': self.default_config,
            'timeout': self.timeout,
            'max_retries': self.max_retries
        } 